seed_everything: 42
model:
  pretrained_model: "hugo/byt5-pt-v4"
  from_flax: true
  use_pretraining: true
  learning_rate: 3e-5
  target_max_length: 5
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_eps: 1e-8
  adam_weight_decay: 0.0
  output_dir: "./output/byt5-pt-assin2/"
data:
  tokenizer_name: "hugo/byt5-pt-v4"
  train_dataset: "assin2"
  train_subdataset: "None"
  validation_set: test
  batch_size: 2
  max_length: 1024
  target_max_length: 5
  xlang_dataset_name: null
  xlang_subdataset_name: null
  xlang_validation_set: null
trainer:
  gpus: 1
  max_epochs: 5
  val_check_interval: 1.0
  gradient_clip_val: 1.0
  accumulate_grad_batches: 2
  precision: 32
  default_root_dir: "./checkpoints"
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
  logger:
    class_path: pytorch_lightning.loggers.NeptuneLogger
    init_args:
      log_model_checkpoints: false
