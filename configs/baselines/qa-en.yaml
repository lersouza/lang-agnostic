seed_everything: 42
data:
  class_path: data_qa.TydiQAGoldPModule
  init_args:
    tokenizer_name: "google/byt5-small"
    batch_size: 8
    max_length: 2048
    max_target_length: 1024
    train_language: en
    dataloader_num_workers: 6
model:
  class_path: model_qa.QuestionAnsweringModel
  init_args:
    pretrained_model_name: "google/byt5-small"
    use_pretrained_weights: true
    max_target_length: 1024
    metric_name: squad
optimizer:
  class_path: transformers.optimization.Adafactor
  init_args:
    lr: 0.0001
    scale_parameter: false
    relative_step: false
trainer:
  gpus: 1
  max_epochs: 10
  accumulate_grad_batches: 4
  precision: 32
  val_check_interval: 0.2
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: qa
  callbacks:
    - class_path: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
      init_args:
        filename: "baseline-qa-en-epoch={epoch}-step={step}-acc={val/accuracy/en:.4f}"
        monitor: "val/accuracy/en"
        mode: "max"
        save_last: true
        auto_insert_metric_name: false
    - class_path: pytorch_lightning.callbacks.early_stopping.EarlyStopping
      init_args:
        monitor: "val/accuracy/en"
        mode: "max"
        patience: 5
