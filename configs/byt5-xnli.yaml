seed_everything: 42
data:
  class_path: data_nli.XnliDataModule
  init_args:
    tokenizer_name: "google/byt5-small"
    batch_size: 2
    max_length: 1024
    target_max_length: 5
model:
  pretrained_model_name: "google/byt5-small"
  use_pretrained_weights: true
  target_max_length: 5
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1e-4
    betas:
      - 0.9
      - 0.999
    eps: 1e-8
    weight_decay: 0.0
trainer:
  gpus: 1
  max_epochs: 5
  val_check_interval: 0.2
  gradient_clip_val: 1.0
  accumulate_grad_batches: 4
  precision: 32
  default_root_dir: "./output/byt5-xnli"
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
      init_args:
        dirpath: ./output/byt5-xnli/checkpoints
        every_n_train_steps: 50000
        save_on_train_epoch_end: false
  logger:
    class_path: pytorch_lightning.loggers.NeptuneLogger
    init_args:
      log_model_checkpoints: false
